version: '3.8'

services:
  # CPU-only version
  fastmoda-cpu:
    build:
      context: .
      dockerfile: Dockerfile
      target: base
    ports:
      - "5000:5000"
    volumes:
      - ./uploads:/app/uploads
      - ./example_sigs:/app/example_sigs:ro
    environment:
      - FLASK_ENV=production
      - USE_GPU=false
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # GPU-enabled version (requires nvidia-docker)
  fastmoda-gpu:
    build:
      context: .
      dockerfile: Dockerfile
      target: gpu
      args:
        - CUDA_VERSION=11.8
    ports:
      - "5001:5000"
    volumes:
      - ./uploads:/app/uploads
      - ./example_sigs:/app/example_sigs:ro
    environment:
      - FLASK_ENV=production
      - USE_GPU=true
      - CUDA_VISIBLE_DEVICES=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    profiles:
      - gpu

  # Development version with hot-reload
  fastmoda-dev:
    build:
      context: .
      dockerfile: Dockerfile
      target: base
    ports:
      - "5000:5000"
    volumes:
      - .:/app
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=1
    command: python app.py
    restart: unless-stopped
    profiles:
      - dev

  # Nginx reverse proxy (optional, for production)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - fastmoda-cpu
    restart: unless-stopped
    profiles:
      - production

volumes:
  uploads:
  example_sigs:

networks:
  default:
    name: fastmoda-network
